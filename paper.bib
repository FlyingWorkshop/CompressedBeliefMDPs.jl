@article{POMDPs.jl,
  author  = {Maxim Egorov and Zachary N. Sunberg and Edward Balaban and Tim A. Wheeler and Jayesh K. Gupta and Mykel J. Kochenderfer},
  title   = {POMDPs.jl: A Framework for Sequential Decision Making under Uncertainty},
  journal = {Journal of Machine Learning Research},
  year    = {2017},
  volume  = {18},
  number  = {26},
  pages   = {1--5},
  url     = {http://jmlr.org/papers/v18/16-300.html}
}

@article{Roy,
   title={Finding Approximate POMDP solutions Through Belief Compression},
   volume={23},
   ISSN={1076-9757},
   url={http://dx.doi.org/10.1613/jair.1496},
   DOI={10.1613/jair.1496},
   journal={Journal of Artificial Intelligence Research},
   publisher={AI Access Foundation},
   author={Roy, N. and Gordon, G. and Thrun, S.},
   year={2005},
   month=jan, pages={1–40} 
}

@article{Kaelbling,
  title = {Planning and acting in partially observable stochastic domains},
  journal = {Artificial Intelligence},
  volume = {101},
  number = {1},
  pages = {99-134},
  year = {1998},
  issn = {0004-3702},
  doi = {https://doi.org/10.1016/S0004-3702(98)00023-X},
  url = {https://www.sciencedirect.com/science/article/pii/S000437029800023X},
  author = {Leslie Pack Kaelbling and Michael L. Littman and Anthony R. Cassandra},
  keywords = {Planning, Uncertainty, Partially observable Markov decision processes},
  abstract = {In this paper, we bring techniques from operations research to bear on the problem of choosing optimal actions in partially observable stochastic domains. We begin by introducing the theory of Markov decision processes (mdps) and partially observable MDPs (pomdps). We then outline a novel algorithm for solving pomdps off line and show how, in some cases, a finite-memory controller can be extracted from the solution to a POMDP. We conclude with a discussion of how our approach relates to previous work, the complexity of finding exact solutions to pomdps, and of some possibilities for finding approximate solutions.}
}

@misc{carbon,
      title={Optimizing Carbon Storage Operations for Long-Term Safety}, 
      author={Yizheng Wang and Markus Zechner and Gege Wen and Anthony Louis Corso and John Michael Mern and Mykel J. Kochenderfer and Jef Karel Caers},
      year={2023},
      eprint={2304.09352},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@article{drugs,
   title={Optimization of Molecules via Deep Reinforcement Learning},
   volume={9},
   ISSN={2045-2322},
   url={http://dx.doi.org/10.1038/s41598-019-47148-x},
   DOI={10.1038/s41598-019-47148-x},
   number={1},
   journal={Scientific Reports},
   publisher={Springer Science and Business Media LLC},
   author={Zhou, Zhenpeng and Kearnes, Steven and Li, Li and Zare, Richard N. and Riley, Patrick},
   year={2019},
   month=jul }

@article{planes,
author = {Larkin Folsom and Masahiro Ono and Kyohei Otsu and Hyoshin Park},
title ={Scalable information-theoretic path planning for a rover-helicopter team in uncertain environments},
journal = {International Journal of Advanced Robotic Systems},
volume = {18},
number = {2},
pages = {1729881421999587},
year = {2021},
doi = {10.1177/1729881421999587},
URL = { https://doi.org/10.1177/1729881421999587 },
eprint = { https://doi.org/10.1177/1729881421999587 },
abstract = { Mission-critical exploration of uncertain environments requires reliable and robust mechanisms for achieving information gain. Typical measures of information gain such as Shannon entropy and KL divergence are unable to distinguish between different bimodal probability distributions or introduce bias toward one mode of a bimodal probability distribution. The use of a standard deviation (SD) metric reduces bias while retaining the ability to distinguish between higher and lower risk distributions. Areas of high SD can be safely explored through observation with an autonomous Mars Helicopter allowing safer and faster path plans for ground-based rovers. First, this study presents a single-agent information-theoretic utility-based path planning method for a highly correlated uncertain environment. Then, an information-theoretic two-stage multiagent rapidly exploring random tree framework is presented, which guides Mars helicopter through regions of high SD to reduce uncertainty for the rover. In a Monte Carlo simulation, we compare our information-theoretic framework with a rover-only approach and a naive approach, in which the helicopter scouts ahead of the rover along its planned path. Finally, the model is demonstrated in a case study on the Jezero region of Mars. Results show that the information-theoretic helicopter improves the travel time for the rover on average when compared with the rover alone or with the helicopter scouting ahead along the rover’s initially planned route. }}

@INPROCEEDINGS{markets,
  author={Jamgochian, Arec L. and Kochenderfer, Mykel J.},
  booktitle={2019 IEEE International Conference on Connected Vehicles and Expo (ICCVE)}, 
  title={Stochastic Model Predictive Control for Scheduling Charging of Electric Vehicle Fleets with Market Power}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  keywords={stochastic programming;model predictive control;electric vehicles;charge scheduling},
  doi={10.1109/ICCVE45908.2019.8965237}}

@book{AFDM,
  title={Algorithms for Decision Making},
  author={Kochenderfer, M.J. and Wheeler, T.A. and Wray, K.H.},
  isbn={9780262370233},
  url={https://books.google.com/books?id=zKtaEAAAQBAJ},
  year={2022},
  publisher={MIT Press}
}

@misc{Julia,
      title={Julia: A Fast Dynamic Language for Technical Computing}, 
      author={Jeff Bezanson and Stefan Karpinski and Viral B. Shah and Alan Edelman},
      year={2012},
      eprint={1209.5145},
      archivePrefix={arXiv},
      primaryClass={cs.PL}
}

@INPROCEEDINGS{SARSOP,
    AUTHOR    = {Hanna Kurniawati, David Hsu, Wee Sun Lee},
    TITLE     = {{SARSOP}: Efficient Point-Based {POMDP} Planning by Approximating Optimally Reachable Belief Spaces},
    BOOKTITLE = {Proceedings of Robotics: Science and Systems IV},
    YEAR      = {2008},
    ADDRESS   = {Zurich, Switzerland},
    MONTH     = {June},
    DOI       = {10.15607/RSS.2008.IV.009} 
}

@inproceedings{EPCA,
 author = {Collins, Michael and Dasgupta, S. and Schapire, Robert E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {T. Dietterich and S. Becker and Z. Ghahramani},
 pages = {},
 publisher = {MIT Press},
 title = {A Generalization of Principal Components Analysis to the Exponential Family},
 url = {https://proceedings.neurips.cc/paper_files/paper/2001/file/f410588e48dc83f2822a880a68f78923-Paper.pdf},
 volume = {14},
 year = {2001}
}

@misc{epca-MATLAB,
title={E-PCA},
author={Guillaume de Chambrier},
url={https://github.com/gpldecha/e-pca},
year={2016}
}

@article{complexity1,
  title={The Complexity of Markov Decision Processes},
  author={Christos H. Papadimitriou and John N. Tsitsiklis},
  journal={Math. Oper. Res.},
  year={1987},
  volume={12},
  pages={441-450},
  url={https://api.semanticscholar.org/CorpusID:29322444}
}

@inproceedings{complexity2,
  title={On the Undecidability of Probabilistic Planning and Infinite-Horizon Partially Observable Markov Decision Problems},
  author={Omid Madani and Steve Hanks and Anne Condon},
  booktitle={AAAI/IAAI},
  year={1999},
  url={https://api.semanticscholar.org/CorpusID:7549144}
}

@inproceedings{grid,
 author = {Davies, Scott},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M.C. Mozer and M. Jordan and T. Petsche},
 pages = {},
 publisher = {MIT Press},
 title = {Multidimensional Triangulation and Interpolation for Reinforcement Learning},
 url = {https://proceedings.neurips.cc/paper_files/paper/1996/file/310ce61c90f3a46e340ee8257bc70e93-Paper.pdf},
 volume = {9},
 year = {1996}
}

@article{kNN,
 ISSN = {03067734, 17515823},
 URL = {http://www.jstor.org/stable/1403797},
 author = {Evelyn Fix and J. L. Hodges},
 journal = {International Statistical Review / Revue Internationale de Statistique},
 number = {3},
 pages = {238--247},
 publisher = {[Wiley, International Statistical Institute (ISI)]},
 title = {Discriminatory Analysis. Nonparametric Discrimination: Consistency Properties},
 urldate = {2024-03-19},
 volume = {57},
 year = {1989}
}

@article{PCA,
  title={Analysis of a complex of statistical variables into principal components.},
  author={Harold Hotelling},
  journal={Journal of Educational Psychology},
  year={1933},
  volume={24},
  pages={498-520},
  url={https://api.semanticscholar.org/CorpusID:144828484}
}

@ARTICLE{kernelPCA,
  author={Schölkopf, Bernhard and Smola, Alexander and Müller, Klaus-Robert},
  journal={Neural Computation}, 
  title={Nonlinear Component Analysis as a Kernel Eigenvalue Problem}, 
  year={1998},
  volume={10},
  number={5},
  pages={1299-1319},
  keywords={},
  doi={10.1162/089976698300017467}}


@article{PPCA,
author = {Tipping, M. E. and Bishop, Christopher},
title = {Probabilistic Principal Component Analysis},
year = {1999},
month = {January},
abstract = {Principal component analysis (PCA) is a ubiquitous technique for data analysis and processing, but one which is not based upon a probability model. In this paper we demonstrate how the principal axes of a set of observed data vectors may be determined through maximum-likelihood estimation of parameters in a latent variable model closely related to factor analysis. We consider the properties of the associated likelihood function, giving an EM algorithm for estimating the principal subspace iteratively, and discuss, with illustrative examples, the advantages conveyed by this probabilistic approach to PCA.},
url = {https://www.microsoft.com/en-us/research/publication/probabilistic-principal-component-analysis/},
pages = {611-622},
journal = {Journal of the Royal Statistical Society, Series B},
volume = {21},
number = {3},
note = {Available from  http://www.ncrg.aston.ac.uk/Papers/index.html},
}
